---
title: Migrating to an Google Cloud SQL for PostgreSQL Instance
owner: Cloud Service Broker for GCP
---

<strong><%= modified_date %></strong>

This topic describes migrating from GCP Relational Database Service (Google Cloud SQL) for
PostgreSQL Instance of the GCP Service Broker for VMware Tanzu tile
to the <%= vars.product_full %> tile.

## <a id='about'></a> About Migrating Data to Google Cloud SQL for PostgreSQL Instance

Because the GCP Service Broker for VMware Tanzu (hereafter: "the legacy broker") tile
is going out of support, it is important to move from PostgreSQL instances that
were created by the legacy broker over to the <%= vars.product_short %>.

The <%= vars.product_short %> plans are configurable.
When migrating, examine the configuration of the plans in use with the legacy broker and create
matching plans in the <%= vars.product_short %>.

You can use the GCP Database Import and Export functionality to migrate data between Google Cloud SQL for PostgreSQL Instances.
The tool copies data from one database to a GCP Bucket and from there to another Database Instance.
Because the original database is not modified, you can reverse the migration if you detect any problems.

### <a id='configuration'></a> Matching Configuration

Both the legacy broker and the <%= vars.product_short %> allow you to customize service plans.
Create plans in the <%= vars.product_short %> that match the plans used in the legacy broker.
It is mandatory for the new Service Instances to be created with the same major version of Postgres as the old instances and with the same (or larger) available disk size.
It may be useful to create a test service instance and compare the properties in the GCP console.
For instructions on how to configure plans, see
[Configure Services with Cloud Service Broker for GCP](installing-with-gcp.html#services).

### <a id='migration'></a> Migrating Data

You might want to migrate data from instances created with the legacy broker to instances
created with the <%= vars.product_short %>.

<p class="note important">
  <strong>Important:</strong> Migration of data might incur app downtime.
  The amount of downtime depends on the method chosen.
</p>

There are many options for performing data migration which include [GCP SQL Import and Export](https://cloud.google.com/sql/docs/postgres/backup-recovery/restoring),
manual data migration, and options available from other vendors.
For more information about the data migration process, refer to the documentation for the option that you choose.

In general, the data migration steps are:

1. Create a backup of the PostgreSQL instance.
1. Create an Google Cloud SQL for PostgreSQL instance using the <%= vars.product_short %>.
1. Restore a backup of the data from a legacy broker PostgreSQL instance into the newly created instance.
1. Unbind apps from the legacy broker PostgreSQL instance and bind them to the newly created instance.
1. After migration is complete, you can stop on-going migration and optionally delete the legacy broker 
   PostgreSQL instance.

For more detailed steps showing the Cloud Foundry and `gcloud` commands necessary to use GCP SQL Import and Export,
see [Migrate Data from a GCP Service Broker for VMware Tanzu PostgreSQL Instance](#steps).

## <a id='steps'></a> Migrate Data from a GCP Service Broker for VMware Tanzu PostgreSQL Instance

To migrate data from an existing legacy PostgreSQL instance to the <%= vars.product_short %>:


<p class="note important">
<strong>Important:</strong> Since GCP SQL Import and Export does not support a streaming / continuos replication you may want
  to consider putting your Application in read only mode while the migration is ongoing. 
</p>


1. Create a bucket (Bucket names need to be lowercase) to hold the backup files.:
   
   ```console
   gsutil mb gs://<BACKUP-BUCKET-NAME>
   ```

1. Get OLD_INSTANCE_ID for the legacy PostgreSQL instance details by running:

    ```console
    cf env APP-USING-LEGACY-SERVICE-INSTANCE
    ```

    Where is `APP-USING-LEGACY-SERVICE-INSTANCE` is the name of an app that is bound to a
    service instance from the legacy broker. Inspect the `VCAP_SERVICES` JSON
    it will contain a property named `database_name`, this is your <OLD_INSTANCE_DB_NAME>, and a property named `instance_name` which is your <OLD_INSTANCE_ID>.

1. Create a new PostgreSQL service instance using <%= vars.product_short %>. You will need to provide the <OLD_INSTANCE_DB_NAME> as a property. Additionally you will have to set the appropriate POSTGRES Version (same os your old service instance)

    ```console
    cf create-service <NEW_SERVICE_BROKER> <SERVICE-INSTANCE-NAME> -c '{"db_name":"<OLD_INSTANCE_DB_NAME>", "database_version": "<OLD_INSTANCE_PG_VERSION>" }'
    ```

1. Determine the GCP Database ID from the `cf service` output:

    ```console
    cf service <SERVICE-INSTANCE-NAME >--guid
    ```

    This will output your CF Service Instance GUID. To get the GCP Database Instance ID you need to prefix the guid with: `csb-postgres-` resulting in a string similar to:

    `csb-postgres-XXXXXXXX-XXXX-XXXX-XXXX-XXXXXXXXXXXX`


1. Create a backup of the old service instance with GCP Import and Export

   ```
   // Give old DB Instance Service Account access to the newly created bucket.

   INSTANCE_SERVICE_ACCOUNT_NAME=$(gcloud sql instances describe <OLD_INSTANCE_ID> --format json | jq .serviceAccountEmailAddress)
   gsutil acl ch -u "${INSTANCE_SERVICE_ACCOUNT_NAME}:W" gs://<BACKUP-BUCKET-NAME>

   // Run the export
   gcloud sql export sql -i <OLD_INSTANCE_ID> "gs://<BACKUP-BUCKET-NAME>/backup.sql" -d <OLD_INSTANCE_DB_NAME>
   ```


1. Prepare the database for the import. GCP Import and Export can cause problems with permissions on DB objects created by activating extensions.


   ```console
   cat <<EOF> prepare.sql
      create role "binding_user_group" with login;
      grant all privileges on all tables in schema public to "binding_user_group";
      grant "cloudsqlsuperuser" to "binding_user_group";
      do language plpgsql
      $$
          declare
              rec record;
          begin
              for rec in
                  select usename into rec from pg_catalog.pg_user where usename not like 'cloud%' and usename != 'postgres'
                  loop
                      execute format('grant "binding_user_group" to %I', rec.usename);
                  end loop;
              for rec in
                  select datname from pg_catalog.pg_database where datname not in ('cloudsqladmin', 'postgres')
                  loop
                      execute format('grant all privileges on database %I to "binding_user_group"', rec.datname);
                  end loop;
          end
      $$
  EOF

  gsutil cp ./prepare.sql "gs://<BACKUP-BUCKET-NAME>/prepare.sql"

  cat <<EOF> cleanup.sql
    alter role "binding_user_group" with nologin
  EOF


  gsutil cp ./cleanup.sql "gs://<BACKUP-BUCKET-NAME>/cleanup.sql"


   ```
      
1. You can optionally check the contents of the export at this point in time by inspecting the contents of the created dump by downloading it via gsutil:


   ```console
     gsutil cp "gs://<BACKUP-BUCKET-NAME>/backup.sql" /path/to/local/copy/of/dump

   ```

   You can inspect the dump with your texteditor / tooling of choice.

1. Restore the backup of the old service instance into the new Service Instance.
   E.g via

   ```
     // Give the new DB Instance Service Account access to the newly created bucket.

     INSTANCE_SERVICE_ACCOUNT_NAME=$(gcloud sql instances describe <NEW_INSTANCE_ID> --format json | jq .serviceAccountEmailAddress)
     gsutil acl ch -u "${INSTANCE_SERVICE_ACCOUNT_NAME}:R" 'gs://<BACKUP-BUCKET-NAME>/*'

     // Run the prepare

     gcloud sql import sql <NEW_INSTANCE_ID> "gs://<BACKUP-BUCKET-NAME>/prepare.sql" -d <OLD_INSTANCE_DB_NAME>

     // Run the import

     gcloud sql import sql <NEW_INSTANCE_ID> "gs://<BACKUP-BUCKET-NAME>/backup.sql" -d <OLD_INSTANCE_DB_NAME> --user binding_user_group
     
     // Run the cleanup

     gcloud sql import sql <NEW_INSTANCE_ID> "gs://<BACKUP-BUCKET-NAME>/cleanup.sql" -d <OLD_INSTANCE_DB_NAME>

   ```

1. Disconnect the app from the legacy service binding by running:

    ```console
    cf unbind-service APP-NAME LEGACY-SERVICE-INSTANCE
    ```

    Where:

    * `APP-NAME` is the app using the PostgreSQL instance.
    * `LEGACY-SERVICE-INSTANCE` is the name of the GCP Service Broker for VMware Tanzu-brokered PostgreSQL instance.

    For example:

    <pre class="terminal">
    $ cf unbind-service my-app my-old-instance
    </pre>

1. Bind the app to the new service instance by running:

    ```console
    cf bind-service APP-NAME NEW-SERVICE-INSTANCE
    ```

    Where `NEW-SERVICE-INSTANCE` is the name of the <%= vars.product_short %> service instance
    that you created in step 2 above.

    For example:

    <pre class="terminal">
    $ cf bind-service my-app my-csb-gcp-instance
    </pre>

    Because <%= vars.product_short %> creates new credentials at bind time,
    this creates new binding credentials for the app.

1. Restage the app:

    ```console
    cf restage APP-NAME
    ```

1. After the migration is successful, you can remove the legacy service instance.
